In the experiments for both the synthetic datasets and the real datasets a group of classifiers were used to determine the correlation between the degradation in classifier performance, and growth in complexity measure. The chosen supervised learning algorithms were support vector machines, random forest, multi-layer perceptron and k-nearest neighbors. All of the implementations came from the Scikit-Learn library for Python. To ensure decent performance for the classifiers the algorithms did for each dataset search through a parameter space to find an optimal solution. The parameter space for each classifier can be found in Table \ref{tab:param_space}. The parameter spaces where parameter optimized using the hyperopt package, with up to $100$ evaluations. In the parameter space for random forest, $m$ is the number of attributes in the dataset. In the parameter space for the multi layer perceptron $a=\frac{m+2}{2}$. These values were taken from the parameter spaces used in Barella et al. \cite{DBLP:journals/isci/BarellaGSLC21}.
\begin{table}[tbp]
    \centering
    \begin{tabular}{lll}
        \toprule
        Algorithm & Parameter & Space \\
        \midrule
        $\knn$ & $k$ & $1,3,5,\dots,31$ \\ 
        \midrule
        MLP & learning rate & $0.1,0.2,0.3,\dots,1$ \\
                            & neurons in hl. & $a-3,a-2,\dots,a+3$ \\
        \midrule
        RF & Trees & $100,200,300,\dots,1000$ \\
           & Variables & $\frac{\sqrt{m}}{2},\sqrt{m},2\sqrt{m}$ \\
        \midrule 
        SVM & kernel & linear, radial, sigmoidal \\
            & gamma & $2^{-10},2^{-9},2^{-8},\dots,2^{10}$ \\
            & degree & $1,2,3,4,5$ \\
        \bottomrule
    \end{tabular}
    \caption{\label{tab:param_space}Classifiers used in the experimental setup, and their respective parameter spaces. Hidden layers is abbreviated as hl.}
\end{table}
In excess of determining the right parameters, each dataset was evaluated using 2 times 5 fold stratified cross validation to ensure stability. 
